<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="cye-nm">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- change the follow href="./photo/youwanttoshowinhead"-->
    <link rel="shortcut icon" href="./photo/youwanttoshowinhead">
    <!-- change the follow content="   "-->
    <meta name="keywords" content="Yue-Xiang LI, Yuexiang Li, homepage">
    <meta name="description" content="Medical Image Analysis">

    <link rel="stylesheet" href="./css/jemdoc.css" type="text/css">
    <!-- change the follow title-->
    <title>Yuexiang LI's Homepage</title>

    <script type="text/javascript" async="" src="./css/ga.js"></script>
    <script type="text/javascript">
        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-39824124-1']);
        _gaq.push(['_trackPageview']);
        (function() {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>

    <style id="nightModeStyle">
        html.cye-enabled.cye-nm:not(*:-webkit-full-screen-ancestor) body,
        html.cye-enabled.cye-nm:not(*:-webkit-full-screen-ancestor) #cye-workaround-body {
            -webkit-filter: contrast(91%) brightness(84%) invert(1);
        }
    </style>
    <style id="cyebody">
        html.cye-enabled.cye-lm body {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="cyediv">
        html.cye-enabled.cye-lm div {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="cyetable">
        html.cye-enabled.cye-lm th {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
        
        html.cye-enabled.cye-lm td {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="cyetextInput">
        html.cye-enabled.cye-lm input[type=text] {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
        
        html.cye-enabled.cye-lm textarea {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="cyeselect">
        html.cye-enabled.cye-lm select {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="cyeul">
        html.cye-enabled.cye-lm ul {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="cyeChangeByClick">
        html.cye-enabled.cye-lm .cye-lm-tag,
        html.cye-enabled.cye-lm.cye-lm-tag {
            background-color: #cce8cf !important;
            border-color: rgb(51, 58, 51) !important;
            background-image: none !important;
            color: #000000 !important
        }
    </style>
    <style id="style-1-cropbar-clipper">
        /* Copyright 2014 Evernote Corporation. All rights reserved. */
        
        .en-markup-crop-options {
            top: 18px !important;
            left: 50% !important;
            margin-left: -100px !important;
            width: 200px !important;
            border: 2px rgba(255, 255, 255, .38) solid !important;
            border-radius: 4px !important;
        }
    </style>
    <script>
        (function(i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function() {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o), m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            }

        )(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-82384246-1', 'auto');
        ga('send', 'pageview');
    </script>
    <!--
        .en-markup-crop-options div div:first-of-type { margin-left: 0px !important; }
    -->
    <style>
        ul.nav {
          list-style-type: none;
          margin: 0;
          padding: 0;
          overflow: hidden;
          background-color: white;
        }
         
        ul.nav li {
          float: left;
        }
         
        ul.nav li a {
          display: inline;
          /* color: white; */
          text-align: center;
          padding: 14px 19px;
          text-decoration: underline;
        }
         
        /* ul.nav li a:hover { */
          /* background-color: #111; */
        /* } */
    </style>
</head>

<body ryt12610="1">
    <!-- <ul class="nav"> -->
    <!-- <li><a href="#Openings"><b>Openings</b></a></li> -->
    <!-- <li><a href="#News"><b>News</b></a></li> -->
    <!-- <li><a href="#EduandExp"><b>Education &amp; Experience</b></a></li> -->
    <!-- <li><a href="#CP"><b>Concurrent Post</b></a></li> -->
    <!-- <li><a href="#Publications"><b>Publications</b></a></li> -->
    <!-- <li><a href="#ProServices"><b>Professional Services</b></a></li> -->
    <!-- <li><a href=documents/Resume-Yuexiang_Li.pdf><b>Full Resume</b></a></li> -->
    <!-- </ul> -->
    <div id="layout-content" style="margin-top:15px">
        <table>
            <tbody>
                <tr>
                    <td width="670">
                        <div id="toptitle">
                            <!-- change the follow as the page iner title-->
                            <h1><a>Yuexiang LI</a> &nbsp; <font class="highlight"><a>李悦翔</a></font> </h1>
                            <h1>

                            </h1>
                        </div>
                        <h3>Professor
                        </h3>
                        <p>
                            <a><b>M</b>edical <b>A</b>I <b>R</b>e<b>S</b>earch (<b>MARS</b>) Group</a> <br>
                            <a>School of Life Sciences and Medical Engineering</a> &nbsp; <font class="highlight"><a>生命科学与医学工程学院</a></font> <br>
							<a href="https://www.gxmu.edu.cn/">Guangxi Medical University</a> &nbsp; <font class="highlight"><a href="https://www.gxmu.edu.cn/">广西医科大学</a></font> <br>
                            <!-- <br> Email: <a href="leeyuexiang@163.com">leeyuexiang@163.com</a><br> -->
                            <br>
                        </p>
                        <h3>Associate Director
                        </h3>
                        <p>
                            <a>University Engineering Research Center of Digital Medicine and Healthcare</a> <br>
                            <font class="highlight"><a>数字医学与健康广西高校工程研究中心</a></font> <br>
							<!-- <a href="https://www.gxmu.edu.cn/">Guangxi Medical University</a> &nbsp; <font class="highlight"><a href="https://www.gxmu.edu.cn/">广西医科大学</a></font> <br> -->
                            <br> Email: <a href="leeyuexiang@163.com">leeyuexiang@163.com</a><br>
                            <br>
                        </p>
                    </td>
                    <td>
                        <div style="float:right">
                            <img src="./images/yuexiangli.jpg" border="0" width="160">
                        </div>
                    </td>
                </tr>
                <tr>
                </tr>
            </tbody>
        </table>
    </div>

    <ul class="nav">
    <li><a href="#Openings"><b>Openings</b></a></li>
    <li><a href="#News"><b>News</b></a></li>
    <li><a href="#EduandExp"><b>Education &amp; Experience</b></a></li>
    <li><a href="#Publications"><b>Publications</b></a></li>
    <li><a href="#ProServices"><b>Professional Services</b></a></li>
    <li><a href=documents/Resume-Yuexiang_Li.pdf><b>Full Resume</b></a></li>
    </ul>

    <article id="Biography" class="wrapper style1">
    <div class="container">
    <div class="row">
    <h2>Biography</h2>
    <p>
        Yuexiang LI currently works in Life Sciences Institute, Guangxi Medical University (GXMU) as a Full Professor. 
        He is the academic leader of the discipline of artificial intelligence, the associate director of University Engineering Research Center of Digital Medicine and Healthcare, and leads the Medical AI ReSearch (MARS) group in GXMU.
        Prof. Li graduated from the University of Nottingham, United Kingdom with a Ph.D., and has been engaged in research on intelligent analysis and processing of medical images (including microscopic images, pathological slices and multimodal medical images) for more than ten years. 
        Before joining GXMU, he worked in Tencent Jarvis Lab as a senior researcher and got excellent connections to industry. Prof. Li has published multiple academic papers in top-tier medical image processing journals (e.g., TMI, MIA) and conferences (e.g., AAAI, ECCV, MICCAI). 
        He is also the reviewer for TPAMI, TMI, MICCAI and the program chair for world-wide conferences. 
    </p>
    </div>
    </div>
    </article>

    <article id="Openings" class="wrapper style1">
    <h2>Openings</h2>
    <p>
        I am always looking for talented and self-motivated students to join my research group to work in the fields of <b>medical image analysis</b>/<b>computer vision</b>/<b>pattern recognition</b>. 
    </p>
    <p>
        Multiple positions of Ph.D program in <a href="https://yjs.gxmu.edu.cn"><b>Guangxi Medical University</b></a> and joint Ph.D program with <a href="https://fds.cityu.edu.mo/en/page-133"><b>City University of Macau</b></a> and the <a href="https://www.nottingham.edu.cn/en/Study-with-us/Postgraduate-research/Programmes/PhD.aspx?id=5c96e60f-219e-4742-93bf-549464f4be0e&language=en-GB"><b>University of Nottingham, Ningbo</b></a> are available. Please feel free to contact via email.
    </p>
    <!-- <p>
        Glad to hold the <a href="https://cosas.grand-challenge.org/"> <b>Cross-Scanner Adenocarcinoma Segmentation (COSAS 2024)</b></a> challenge (Finished) as one of the Leading Organizers. The winners will be announced in the satellite event of <a href="https://conferences.miccai.org/2024/en/">MICCAI 2024</a>. </b>
    </p> -->
    <!-- <p>
        <font class="highlight"><a href=https://mp.weixin.qq.com/s?__biz=MzkzNDI0MTYzOA==&mid=2247487658&idx=1&sn=31ca85efd44eb0707b7610007cf621da&chksm=c24164a3f536edb54ceccbafd2af897eac48fee8b5de529bccace2bf63d3c132a598d5677a2e&mpshare=1&scene=23&srcid=1001DwrbfmLAlu1HHqQXyGxx&sharer_shareinfo=0c5f8450db4c8cfb8b2fed0fbe1b71fb&sharer_shareinfo_first=32c80afaf30f3eadc23e917124527331#rd>2024 硕士/博士招生中，欢迎生物医学工程/医学相关专业考生报考！</a></font>
    </p> -->
    <p>
        Multiple positions of postdoctoral fellow and research assistant are now available (should be in the fields related to bio-medical engineering/computer science/electronic engineering).
    </p>
    <p>
        <font class="highlight"><a href=https://mp.weixin.qq.com/s/IrsQUNcF8ZVh1AS0H_t_EQ>招聘多名博士后和研究助理，待遇从优，优秀者可获事业编制！（有意者可电邮垂询）</a></font>
    </p>
    </article>

    <article id="News" class="wrapper style1">
	<h2>News</h2>
    <ul>
        <li>
            Sep 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> Selected as <a href='https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/8'>"Stanford's Top 2% Scientist (2025)"</a> </b>
        </li>
        <li>
            Sep 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by IEEE Transactions on Medical Imaging (IF: 9.800) </b>
        </li>
        <li>
            Sep 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> Glad to serve as a Master/Ph.D Supervisor in <a href='http://jyt.gxzf.gov.cn/jyxw/jyyw/t25912779.shtml'>Guangxi Academy of Artificial Intelligence</a> </b>
        </li>
        <li>
            Aug 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> Glad to serve as a Senior Program Committee for AAAI (CCF-A) 2026 </b>
        </li>
        <li>
            Jun 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> Two papers are accepted by MICCAI (CCF-B) 2025 </b>
        </li>
        <li>
            Jun 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> Got a grant (600,000) from Guangxi Government </b>
        </li>
        <li>
            Mar 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> Two papers are accepted by CVPR (CCF-A) 2025 </b>
        </li>
        <li>
            Mar 2025 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by Pattern Recognition (IF: 7.500) </b>
        </li>
         <!--
        <li>
            Nov 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> I would join University of Macau as an Associate Researcher (visiting) shortly </b>
        </li> 
        -->
        <!--
        <li>
            Sep 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> Got a grant (<font class="highlight"><a href=https://kjj.nanning.gov.cn/tzgg/tz/file2024/t5877189.html>邕江计划-领军人才</a></font>) from Nanning City Science and Technology Bureau </b>
        </li>
        <li>
            Aug 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by ACM MM (CCF-A) 2024 </b>
        </li>
        <li>
            Jun 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> Two papers are accepted by MICCAI (CCF-B) 2024 </b>
        </li>
        <li>
            May 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by International Journal of Computer Vision (IF: 19.500) </b>
        </li>
        <li>
            May 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by IEEE Transactions on Multimedia (IF: 7.300) </b>
        </li>
        <li>
            Feb 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by CVPR (CCF-A) 2024 </b>
        </li>
        <li>
            Feb 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by Artificial Intelligence In Medicine (IF: 7.400) </b>
        </li>
        <li>
            Jan 2024 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by IEEE Journal of Biomedical and Health Informatics (IF: 7.700) </b>
        </li>
        <li>
            Dec 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> Two papers are accepted by AAAI (CCF-A) 2024 </b>
        </li>
        <li>
            Dec 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by Pattern Recognition (IF: 8.000) </b>
        </li>
        <li>
            Sep 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> Two papers are accepted by NeurIPS (CCF-A) 2023 </b>
        </li>
        <li>
             Aug 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by Medical Image Analysis (IF: 13.828) </b>
       </li>
		<li>
             Jul 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> Two papers are accepted by ICCV (CCF-A) 2023 </b>
        </li>

		<li>
             Jun 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by MICCAI 2023 </b>
        </li>
		<li>
             Jun 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is accepted by Medical Image Analysis (IF: 13.828) </b>
        </li>
        <li>
             Apr 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is published by Medical Image Analysis (IF: 13.828) </b>
        </li>
        <li>
             Feb 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> Three papers are accepted by CVPR 2023 </b>
        </li>
		<li>
             Jan 2023 &nbsp;&nbsp;&nbsp;&nbsp;<b> One paper is published by IEEE Transactions on Neural Networks and Learning Systems (IF: 14.255)</b>
        </li>
        -->
    </ul>
    </article>

    <article id="EduandExp" class="wrapper style1">
    <h2>Education &amp; Experience</h2>
    <ul>
        <li>
            2024-Present &nbsp;&nbsp;&nbsp;&nbsp;<b>University Engineering Research Center of Digital Medicine and Healthcare, Nanning</b>
            <p><font class="highlight"><a>数字医学与健康广西高校工程研究中心</a></font></p>
        </li>
        Associate Director

        <!-- <li>
            2024-Present &nbsp;&nbsp;&nbsp;&nbsp;<b>Guangxi Institute of Precision Medicine, Nanning</b>
            <p><font class="highlight"><a href="https://www.pmigx.cn">广西精准医学产业技术研究院</a></font></p>
        </li>
        Principal Scientist on Artificial Intelligence, Project Consultant -->

	    <li>
            2023-Present &nbsp;&nbsp;&nbsp;&nbsp;<b>Guangxi Medical University, Nanning</b>
            <p><font class="highlight"><a href="https://sky.gxmu.edu.cn">广西医科大学生命科学与医学工程学院（即生命科学研究院）</a></font></p>
        </li>
        Full Professor, Academic Leader of the discipline of Artificial Intelligence, MARS Group Lead

        <li>
            2024.08-2024.10 &nbsp;&nbsp;&nbsp;&nbsp;<b>MEDIA Lab, Guangdong Provincial People's Hospital, Guangzhou</b>
            <p><font class="highlight"><a href="http://gdphmedialab.cn">广东省医学影像智能分析与应用重点实验室</a></font></p>
        </li>
        Visiting Professor

        <li>
            2019-2023 &nbsp;&nbsp;&nbsp;&nbsp;<b>Tencent Jarvis Lab, Shenzhen</b>
            <p><font class="highlight"><a href="https://jarvislab.tencent.com/">腾讯天衍研究中心</a></font></p>
        </li>
        Senior Researcher, Directed by <a href="https://sites.google.com/site/yefengzheng">Yefeng Zheng</a>, IEEE Fellow

        <li>
            2018-2019 &nbsp;&nbsp;&nbsp;&nbsp;<b>YouTu Lab, Tencent, Shenzhen</b>
            <p><font class="highlight"><a href="https://open.youtu.qq.com/#/open">腾讯优图实验室</a></font></p>
        </li>
        Senior Researcher, Directed by <a href="https://jiaya.me/">Jiaya Jia</a>, IEEE Fellow

		<li>
            2016-2018 &nbsp;&nbsp;&nbsp;&nbsp;<b>Shenzhen University, Shenzhen</b>
        </li>
        Postdoctoral Fellow
		
        <li>
            2012-2016 &nbsp;&nbsp;&nbsp;&nbsp;<b>The University of Nottingham, United Kingdom</b>
        </li>
        Ph.D.

        <li>
            2011-2012 &nbsp;&nbsp;&nbsp;&nbsp;<b>The Hong Kong University of Science and Technology, Hong Kong</b>
        </li>
        M.Sc.

        <li>
            2007-2011 &nbsp;&nbsp;&nbsp;&nbsp;<b>Beijing University of Posts and Telecommunications, Beijing</b>
        </li>
        B.Eng.
    </ul>
    </article>

    <article id="Publications" class="wrapper style1">
    <h2>Selected Journal Paper <small>[For full list, please refer to <a href="https://scholar.google.com/citations?user=WsKu4EMAAAAJ&hl=en">Google Scholar</a> / <a href="https://www.researchgate.net/profile/Yuexiang-Li">ResearchGate</a>]</small></h2>
            <ol>

                <li>
                    <a href="">Multi-constraint transferable generative adversarial networks for cross-modal brain image synthesis</a> <br>
                    <b>Yawen Huang#, Hao Zheng, Yuexiang Li*, Feng Zheng, Xiantong Zhen, GuoJun Qi, Ling Shao, Yefeng Zheng*</b>
                    <em>International Journal of Computer Vision</em>, 2024. (IF: 19.500)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

                <li>
                    <a href="">Cross-modal vertical federated learning for MRI reconstruction</a> <br>
                    <b>Yunlu Yan#, Hong Wang#, Yawen Huang, Nanjun He, Lei Zhu*, Yong Xu, Yuexiang Li*, Yefeng Zheng</b>
                    <em>IEEE Journal of Biomedical and Health Informatics</em> (<b>IEEE JBHI</b>), 2024. (IF: 7.700)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

                <li>
                    <a href="">Triplet-branch network with contrastive prior-knowledge embedding for disease grading</a> <br>
                    <b>Yuexiang Li#*, Yanping Wang, Guang Lin, Yawen Huang, Jingxin Liu, Yi Lin, Dong Wei, Qirui Zhang, Kai Ma et al.</b>
                    <em>Artificial Intelligence In Medicine</em>, 2024. (IF: 7.500)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

                <li>
                    <a href="">Anomaly detection via gating highway connection for retinal fundus images</a> <br>
                    <b>Wentian Zhang#, Haozhe Liu#, Jinheng Xie, Yawen Huang, Yu Zhang, Yuexiang Li*, Raghavendra Ramachandra, Yefeng Zheng</b>
                    <em>Pattern Recognition</em>, 2023. (IF: 8.000)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>
			
                <li>
                    <a href="">Unsupervised domain adaptation for medical image segmentation by disentanglement learning and self-training</a> <br>
                    <b>Qingsong Xie#, Yuexiang Li#, Nanjun He*, Munan Ning, Kai Ma, Guoxing Wang et al.,</b>
                    <em>IEEE Transactions on Medical Imaging</em> (<b>IEEE TMI</b>), 2022. (IF: 11.037)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>
				<li>
                    <a href=""> Beyond mutual information: Generative adversarial network for domain adaptation using information bottleneck constraint</a> <br>
                    <b>Jiawei Chen#, Ziqi Zhang#, Xinpeng Xie#, Yuexiang Li*, Tao Xu, Kai Ma, and Yefeng Zheng,</b>
                    <em>IEEE Transactions on Medical Imaging</em> (<b>IEEE TMI</b>), 2021. (IF: 11.037)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

				<li>
                    <a href=""> DICDNet: Deep interpretable convolutional dictionary network for metal artifact reduction in CT images</a> <br>
                    <b>Hong Wang#, Yuexiang Li*, Nanjun He, Kai Ma, Deyu Meng*, and Yefeng Zheng,</b>
                    <em>IEEE Transactions on Medical Imaging</em> (<b>IEEE TMI</b>), 2021. (IF: 11.037)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

				<li>
                    <a href=""> Anomaly detection for medical images using self-supervised and translation-consistent features</a> <br>
                    <b>He Zhao#, Yuexiang Li*, Nanjun He, Kai Ma, Leyuan Fang, Huiqi Li* et al.,</b>
                    <em>IEEE Transactions on Medical Imaging</em> (<b>IEEE TMI</b>), 2021. (IF: 11.037)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

            </ol>
	

	<h2>Selected Conference Paper <small>[For full list, please refer to <a href="https://scholar.google.com/citations?user=WsKu4EMAAAAJ&hl=en">Google Scholar</a> / <a href="https://www.researchgate.net/profile/Yuexiang-Li">ResearchGate</a>]</small></h2>
            <ol>
                
                <li>
                    <a href="">Hallucinated style distillation for single domain generalization in medical image segmentation</a> <br>
                    <b>Jingjun Yi#, Qi Bi, Hao Zheng*, Haolan Zhan, Wei Ji, Yawen Huang, Shaoxin Li, Yuexiang Li*, Yefeng Zheng, Feiyue Huang,</b>
                    <em>International Conference on Medical Image Computing and Computer Assisted Interventions</em> (<b>MICCAI</b>), 2024. (CCF-B)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

                <li>
                    <a href="">Learning generalized medical image segmentation from decoupled feature queries</a> <br>
                    <b>Qi Bi#, Jingjun Yi#, Hao Zheng*, Wei Ji, Yawen Huang, Yuexiang Li*, Yefeng Zheng,</b>
                    <em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2024. (CCF-A)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

                <li>
                    <a href="">BoxDiff: Text-to-image synthesis with training-free box-constrained diffusion</a> <br>
					<b>Jinheng Xie#, Yuexiang Li*, Yawen Huang, Haozhe Liu, Wentian Zhang, Yefeng Zheng, Mike Zheng Shou*,</b>
                    <em>International Conference on Computer Vision</em> (<b>ICCV</b>), 2023. (CCF-A)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

                <li>
                    <a href="">Dynamically masked discriminator for GANs</a> <br>
                    <b>Wentian Zhang#, Haozhe Liu#, Bing Li*, Jinheng Xie, Yawen Huang, Yuexiang Li*, Yefeng Zheng, Bernard Ghanem,</b>
                    <em>Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023. (CCF-A)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>
                
                <li>
                    <a href="">AdaptiveMix: Improving GAN training via feature space shrinkage</a> <br>
                    <b>Haozhe Liu#, Wentian Zhang#, Bing Li*, Haoqian Wu, Nanjun He, Yawen Huang, Yuexiang Li*, Bernard Ghanem, Yefeng Zheng,</b>
                    <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2023. (CCF-A)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

				<li>
                    <a href="">Combating mode collapse in GANs via manifold entropy estimation</a> <br>
                    <b>Haozhe Liu#, Bing Li*, Haoqian Wu, Hanbang Liang, Yawen Huang, Yuexiang Li*, Bernard Ghanem, Yefeng Zheng,</b>
                    <em>AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2023. (CCF-A)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

				<li>
                    <a href="">Adaptive convolutional dictionary network for CT metal artifact reduction</a> <br>
                    <b>Hong Wang#, Yuexiang Li*, Deyu Meng*, and Yefeng Zheng,</b>
                    <em>International Joint Conference on Artificial Intelligence</em> (<b>IJCAI</b>), 2022. (CCF-A)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>

				<li>
                    <a href="">A multi-task network with weight decay skip connection training for anomaly detection in retinal fundus images</a> <br>
                    <b>Wentian Zhang#, Xu Sun#*, Yuexiang Li#, Haozhe Liu, Nanjun He, Feng Liu* et al.,</b>
                    <em>International Conference on Medical Image Computing and Computer Assisted Interventions</em> (<b>MICCAI</b>), 2022. (CCF-B)<br>
                    <p style="margin-top:3px">
                    </p>
                </li>
                
            </ol>
    </article>
   
    <!-- <h2>Recent Interns @ Tencent</h2>
    <ul>
        <li>
            Jinheng Xie (Dec. 2022 - Jul. 2023) Current Ph.D. candidate in National University of Singapore, supervised by <a href="https://sites.google.com/view/showlab">Mike Z. Shou</a>
        </li>
        <li>
            Wentian Zhang (Sep. 2021 - Jul. 2023) Current Ph.D. candidate in University of Chinese Academy of Sciences, supervised by <a href="https://ling-shao.github.io">Ling Shao</a>
        </li>
        <li>
            Yunlu Yan (Aug. 2021 - Oct. 2022) Current Ph.D. candidate in Hong Kong University of Science and Technology (Guangzhou), supervised by <a href="https://sites.google.com/site/indexlzhu/home">Lei Zhu</a>
        </li>
        <li>
            Haozhe Liu (Aug. 2021 - Jul. 2022) Current Ph.D. candidate in King Abdullah University of Science and Technology, supervised by <a href="https://people.idsia.ch/~juergen/">Jürgen Schmidhuber</a>
        </li>
    </ul> -->

    <h2>Teaching</h2>
    <ul>
        <li> 
            <b>Introduction to Intelligent Medical Engineering</b>, Undergraduate Course, 2024 Fall
        </li>

        <li> 
            <b>Introduction to Biomedical Engineering</b>, Undergraduate Course, 2024 Fall
        </li>

        <li> 
            <b>Artificial Intelligence in Medical Applications</b>, Postgraduate Course, (2023, 2024) Fall
        </li>
    </ul>

	<h2>Grants</h2>
		<ol>
        <li>
            <b><font class="highlight">Principle Investigator</font>, Guangxi Government, 600,000, 2025-2027</b>
        </li>
        <li>
            <b><font class="highlight">Principle Investigator</font>, Natural Science Foundation of Guangxi, 100,000, 2025-2027</b>
        </li>
        <li>
			<b><font class="highlight">Principle Investigator</font>, Nanning City Science and Technology Bureau, 500,000, 2024-2027</b>
		</li>

<!--		<li>-->
<!--			<b><font>Participant</font>, Technical Innovation 2030-"New Generation Artificial Intelligence" Project, 14,890,000, 2020-2024</b>-->
<!--		</li>-->
		
		<li>
			<b><font class="highlight">Principle Investigator</font>, Natural Science Foundation of China, 240,000, 2018-2021</b>
		</li>

		<li>
			<b><font class="highlight">Principle Investigator</font>, Postdoctoral Science Foundation of China, 50,000, 2017-2018</b>
        </li>

        <li>
            <b><font class="highlight">Principle Investigator</font>, Nanning City Science and Technology Bureau, 200,000, 2017-2018</b>
        </li>

		</ol>

    <h2>Award</h2>
	    <ol>
		<li> <b><font class="highlight">First Prize</font></b>, <a>Cerebral Aneurysm Detection Challenge @ MICCAI</a>, 2020</li>
        <li> <b><font class="highlight">First Prize</font></b>, <a>Angle Closure Glaucoma Evaluation Challenge @ MICCAI</a>, 2019</li>
        <li> <b><font class="highlight">First Prize</font></b>, <a>HEp-2 Indirect Immuno-Fluorescence Contest @ ICPR</a>, 2016</li>
	    </ol>
    
    <article id="ProServices" class="wrapper style1">
    <h2>Professional Services</h2>
    <ul>
        <li><em>Stanford's Top 2% Scientist </em> (<b>2022, 2023, 2024, 2025</b>)</li>
        <li><em>Editorial Board, Discover Artificial Intelligence </em> (<b>2025</b>)</li>
        <li><em>Program Committee, MICS </em> (<b>2025</b>)</li>
        <li><em>Leading Organizer, Cross-Scanner Adenocarcinoma Segmentation (COSAS 2024) Challenge @ MICCAI </em> (<b>2024</b>)</li>
		<li><em>Area Chair, MICCAI (CCF-B) </em> (<b> 2023, 2024</b>)</li>
        <li><em>Senior Program Committee, AAAI (CCF-A) </em> (<b> 2026</b>)</li>
        <li><em>Senior Program Committee, IJCAI (CCF-A) </em> (<b> 2023, 2024, 2025</b>)</li>
        <li><em>Committee Member, Guangxi Bioinformatics Society (广西生物信息学学会)</em> (<b> 2024 - 2028</b>)</li>
    </ul>
    </article>

    <h2>Collaborators</h2>
    <ul>
        <li> Company: Tencent YouTu (<b>腾讯优图</b>), Tencent Jarvis Research Center (<b>腾讯天衍</b>), OPPO, Huawei (<b>华为</b>), ByteDance (<b>字节跳动</b>)...</li>

        <li> University: University of Nottingham (UK), University of Birmingham (UK), Durham University (UK), The Hong Kong University of Science and Technology (Hong Kong & Guangzhou), King Abdullah University of Science and Technology (Saudi Arabia)...</li>
        <p style="margin-top:3px">
		</p>
    </ul>

    <div align="center"><img src="./images/gxmu_logo.png" border="0" width="300"></div>

    <p>
    </p>

    <div align="center">
        © 2022-2024 yuexiangli.github.io. All rights reserved.
    </div>
    <p>
    </p>
</body>
</html>
